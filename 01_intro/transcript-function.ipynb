{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# I need to visualize all the environment varibale defined\n",
    "# in the notebook. I need to know the order of the cells\n",
    "# and the order of the variables defined in each cell.\n",
    "\n",
    "os.environ.pop(\"OPENAI_API_BASE\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries and especially load environment variables\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "# set an environment varibale\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"01_basic\"\n",
    "\n",
    "print(os.getenv(\"AZURE_ENDPOINT\"))\n",
    "print(os.getenv(\"OPENAI_API_BASE\"))\n",
    "# I need to clear the OPENAI_API_BASE variable\n",
    "\n",
    "os.environ.pop(\"OPENAI_API_BASE\", None)\n",
    "print(os.getenv(\"OPENAI_API_BASE\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LLM based on GPT4 deployed on Azure\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-09-01-preview\",\n",
    "    deployment_name=\"Gpt35_2\", \n",
    "    azure_endpoint=os.getenv(\"AZURE_ENDPOINT\"),\n",
    "    model_name=\"gpt-3.5-turbo-1106\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I the import my custom function to work with audio and videp\n",
    "from plugins.AudioVideo import AudioVideo\n",
    "\n",
    "audio_video = AudioVideo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plugins.Summarization import Summarization\n",
    "summarization = Summarization()\n",
    "\n",
    "# summarization.summarize_timeline(\"\"\" 00:00\t Hi and welcome again to a new video about UBQI, in which I deal with a question I got quite often and the question is why I cannot use advanced features like\n",
    "# 00:14\t SSH key stored in my UBQI when I work in Windows, it seems not supported. So what is the problem?\n",
    "# 00:22\t This problem usually does not happen in Linux because Linux notively has a support for SSH so when you update your Linux machine,\n",
    "# 00:31\t usually you will receive the latest version of the open SSH protocol that supports UBQI and you have not problem.\n",
    "# 00:39\t In Windows, this situation is a little different. Let me show you why.\n",
    "# 00:45\t In the vast majority of C2H shown, the problem is not having the latest version of SSH\n",
    "# 00:50\t and to verify this open a Windows terminal and type SSH, sorry, SSH-cabbital day.\n",
    "# 00:58\t And if you did not ever install or upgrade SSH, this is the answer.\n",
    "# 01:06\t The answer is open SSH for Windows 8.6 and this is indeed too old to support your UBQI.\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then create tools list\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=audio_video.extract_audio,\n",
    "        name=\"ExtractAudio\",\n",
    "        description=\"extract audio in wav format from an mp4 file\",\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=audio_video.transcript_timeline,\n",
    "        name=\"TranscriptTimeline\",\n",
    "        description=\"Transcript audio from a wav file to a timeline\",\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=summarization.summarize_timeline,\n",
    "        name=\"SummarizeTimeline\",\n",
    "        description=\"Take a transcribed timeline and create a summarized timeline.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "agentFunction =  create_openai_functions_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agentFunction, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor({\n",
    "    \"input\": \"I need a summarized timeline from video c:\\\\temp\\\\300.mp4\"})\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
